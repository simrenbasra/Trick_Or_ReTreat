{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Using Open AI Gym\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Overview\n",
    "\n",
    "In this notebook, I will practice implementing basic concepts of Reinforcement Learning using OpenAI's Gymnasium and Stable Baselines3 library.\n",
    "\n",
    "I will be using **Lunar Lander**. Below is an introduction to the model based on OpenAI Gymnasium's documentation:\n",
    "\n",
    "1. Action Space\n",
    "\n",
    "    The agent can take 4 discrete(fixed) actions:\n",
    "    \n",
    "        - 0: Do nothing\n",
    "        - 1: Fire left engine\n",
    "        - 2: Fire main engine\n",
    "        - 3: Fire right engine\n",
    "\n",
    "2. Observation Space\n",
    "\n",
    "    - Defined as `Box([ -2.5 -2.5 -10. -10. -6.2831855 -10. -0. -0. ], [ 2.5 2.5 10. 10. 6.2831855 10. 1. 1. ], (8,), float32)` \n",
    "    - Observation is 8 dimenstional vector:\n",
    "        1. X position\n",
    "        2. Y position\n",
    "        3. X velocity\n",
    "        4. Y velocity\n",
    "        5. Angle of lander\n",
    "        6. Angular velocity - how tilted the lander is\n",
    "        7. Left Left - if left leg contacts the ground 1 yes 0 no\n",
    "        8. Right Left - if right leg contacts the ground 1 yes 0 no\n",
    "    - 2 copies, first is lower bound, second is upper bound\n",
    "\n",
    "3. Reward\n",
    "\n",
    "    - Goal is to land between the two flags\n",
    "    - Rewards for each step:\n",
    "        - increases closer the lander is to the lander pad\n",
    "        - increaes the slower the lander is mocing \n",
    "        - decreases the more tilted the lander is\n",
    "        - increases by 10 points for each leg in contact with the ground\n",
    "        - decreased by 0.03 points each time a side engine fires (seen as red dots on rendering)\n",
    "        - decreased by 0.3 points each time the main engine fires \n",
    "        - additional -100/+100 points for crashing/safe landing \n",
    "\n",
    "4. Episode End\n",
    "\n",
    "    - Truncation: Reached when agent scores 200 points\n",
    "    - Terminataion: If lander crashes, if lander goes out of bounds or if the lander is asleep.\n",
    "\n",
    "To establish a baseline performance , I will first implement a random policy that randomly selects actions from the action space.\n",
    "\n",
    "I will then progress to training the agent using the Proximal Policy Optimization (PPO) algorithm from Stable Baselines3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Open AI imports\n",
    "import gymnasium as gym\n",
    "\n",
    "# Stable Baseline3 imports\n",
    "from stable_baselines3 import PPO # ALGORITHM: Proximal Policy Optimization \n",
    "from stable_baselines3.common.vec_env import DummyVecEnv # train RL agent on multiple env same time, increase speed, wrapper around env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy # Avagerage reward certain epsidoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lunar Landar : Random Action Selection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising environment using .make() class\n",
    "# Setting render_mode here to humnan to visualise actions occuring during each step, no need to render env later if set here\n",
    "env = gym.make('LunarLander-v2', render_mode = 'human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 Score:-181.52075692708445\n",
      "Episode 2 Score:-85.50182759128737\n",
      "Episode 3 Score:-146.11270119908824\n",
      "Episode 4 Score:-255.29040960121307\n",
      "Episode 5 Score:-261.2332003385057\n"
     ]
    }
   ],
   "source": [
    "# Set the number of episodes and limiting steps per episode for quicker runtime\n",
    "episodes = 5 \n",
    "max_steps = 1000  \n",
    "\n",
    "# Loop through each episode, resetting env after each episode has ran\n",
    "for episode in range(1, episodes+1):\n",
    "    init_obs, init_info = env.reset()\n",
    "    score = 0\n",
    "\n",
    "    # Loop through each step in max_steps\n",
    "    for step in range(max_steps): \n",
    "        # Select rand action from action_space using .sample() \n",
    "        r_action = env.action_space.sample()\n",
    "\n",
    "        # Get info from environment after taking rand action\n",
    "        obs, reward, terminated, truncated, info = env.step(r_action)  \n",
    "        # adding reward to score\n",
    "        score+=reward\n",
    "\n",
    "        # Episode is over if either of flags are set, break if true\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    \n",
    "    # Returning Episode number and score\n",
    "    print(f'Episode {episode} Score:{score}')\n",
    "\n",
    "# Closing environment once done\n",
    "env.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**Comment:**\n",
    "\n",
    "Each episode's score is negative. \n",
    "\n",
    "From this, it is clear that the agent was unable to achieve the goal through taking random actions.\n",
    "\n",
    "This shows the need of training for the agent to understand its environemnt and make informed action choices based on its observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lunar Landar : Training using PPO Algorithm\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is PPO?**\n",
    " \n",
    "PPO stands for Proximal Policy Optimisation. \n",
    "\n",
    "PPO is a policy based algorithm meaning it learns a policy by optimising probability of taking high rewarding actions. \n",
    "\n",
    "After the first episode, the agent has a policy based on what the agent has observed in its environment. The agent starts the next episode and continues to collect observations recording the rewards of each action. PPO calculates the reward of each action and compares it to the expected outcome (this would be previous result). PPO uses these values to update the action probabilites to increase the likelihood of taking actions which give higher rewards. If the difference between the actions are too drastic, PPO 'clips' them to ensure stable learning. \n",
    "\n",
    "**Why PPO?**\n",
    "\n",
    "I chose PPO as my starting point in Reinforcement Learning because it’s both relatively simple and stable. PPO makes gradual, controlled updates to the policy, so the agent doesn’t make drastic changes all at once. \n",
    "\n",
    "In stable baselines 3 documemntation there is also a table to help choose algorithms to use based on the environment and action space you are working with: https://stable-baselines.readthedocs.io/en/master/guide/algos.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorising Env "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I start training, I need to vectorise the environment. \n",
    "\n",
    "Vectorising the environment allows running of multiple instances of an environment at the same time. So intead of training an agent on one Mountain Car environment, I now can train it on 8 environments simultaneously. This means I can get more data in less time and speed up the training process!\n",
    "\n",
    "In this notebook I use `DummyEnvVec` as its a simple wrapper to add to the environment and simple to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorising environment using DummyVecEnv to create 4 instances\n",
    "# Choosing not to render env during training for 2 reasons:\n",
    "v_env = DummyVecEnv([lambda: gym.make('LunarLander-v2') for i in range(4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# File path to save log to\n",
    "log_path = ('../../Training/Logs/')\n",
    "# Using MlpPolicy as environment is relatively simple\n",
    "# To save logs to log path above, to be used later for TensorBoard\n",
    "model = PPO('MlpPolicy', v_env, verbose = 3, tensorboard_log= log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ../../Training/Logs/PPO_12\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 13338 |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 0     |\n",
      "|    total_timesteps | 8192  |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6604         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075129373 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -0.00138     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 780          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    value_loss           | 1.28e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5780        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009114981 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 411         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    value_loss           | 983         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5438        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010344057 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 220         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    value_loss           | 385         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5189        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011881268 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 296         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5019        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013099375 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.4        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 262         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4909        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013574289 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.6        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4885        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012578349 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    value_loss           | 316         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4871        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007090344 |\n",
      "|    clip_fraction        | 0.0806      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 174         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    value_loss           | 277         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 4867       |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00971747 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.777      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 35.6       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    value_loss           | 96.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4863        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011806522 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00948    |\n",
      "|    value_loss           | 87          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4857        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005861165 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    value_loss           | 75.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4853        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007988435 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4851        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006881715 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4847        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009873543 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.63        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 4814       |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 27         |\n",
      "|    total_timesteps      | 131072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00853152 |\n",
      "|    clip_fraction        | 0.0984     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | 0.842      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12.8       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.00413   |\n",
      "|    value_loss           | 30.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 4783       |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 139264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00865306 |\n",
      "|    clip_fraction        | 0.0978     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0.783      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.57       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.00468   |\n",
      "|    value_loss           | 43.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4748        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011259442 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.75        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4726        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008153904 |\n",
      "|    clip_fraction        | 0.096       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.24        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00489    |\n",
      "|    value_loss           | 7.68        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4722         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073233433 |\n",
      "|    clip_fraction        | 0.0864       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    value_loss           | 18.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4727         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092760585 |\n",
      "|    clip_fraction        | 0.0938       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.993       |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.78         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    value_loss           | 27.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4731        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012702694 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.984      |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.96        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4734        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007905883 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.964      |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4737         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045292927 |\n",
      "|    clip_fraction        | 0.0567       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.932       |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.6         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.000923    |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4728         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054003997 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.896       |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    value_loss           | 41.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4695        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005422432 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.964      |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.19        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4683         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048074797 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.923       |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 59.1         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00082     |\n",
      "|    value_loss           | 11           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4686        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006459285 |\n",
      "|    clip_fraction        | 0.0616      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.922      |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    value_loss           | 69.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4690        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009149294 |\n",
      "|    clip_fraction        | 0.0871      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.886      |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.3         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4693        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005280126 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.78       |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4696        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003570624 |\n",
      "|    clip_fraction        | 0.0308      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.733      |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4699         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069152336 |\n",
      "|    clip_fraction        | 0.0587       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.745       |\n",
      "|    explained_variance   | 0.779        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 66.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4702        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018004423 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.703      |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.13        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    value_loss           | 60.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4689        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009303645 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.708      |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    value_loss           | 87.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4677        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013728363 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.664      |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4679        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011684144 |\n",
      "|    clip_fraction        | 0.0736      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.754      |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4681        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005314071 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.699      |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.47        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    value_loss           | 64.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4684        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004043161 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.699      |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.1        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    value_loss           | 88.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4676        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004667333 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.695      |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.33        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    value_loss           | 98.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4672        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008008752 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.673      |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.000397   |\n",
      "|    value_loss           | 48.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4672         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 335872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054982025 |\n",
      "|    clip_fraction        | 0.0467       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.7         |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 126          |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.000818    |\n",
      "|    value_loss           | 82.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4675        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009124517 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.679      |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.3         |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4678        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004766606 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.000638   |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4676         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 360448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035365103 |\n",
      "|    clip_fraction        | 0.0371       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.692       |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 35.8         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.000657    |\n",
      "|    value_loss           | 58.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4676        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004421849 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.701      |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.000354   |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4679         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045994828 |\n",
      "|    clip_fraction        | 0.0601       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.733       |\n",
      "|    explained_variance   | 0.753        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 52.7         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    value_loss           | 85           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4680         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 385024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054305065 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.699       |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 78.7         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4681        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011409718 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    value_loss           | 68.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4682        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005937103 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.679      |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.000126   |\n",
      "|    value_loss           | 58.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4685         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048529264 |\n",
      "|    clip_fraction        | 0.0738       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.707       |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.000581    |\n",
      "|    value_loss           | 28.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4686         |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 417792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044669416 |\n",
      "|    clip_fraction        | 0.0467       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.701       |\n",
      "|    explained_variance   | 0.879        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.000621    |\n",
      "|    value_loss           | 70.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4688         |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062225647 |\n",
      "|    clip_fraction        | 0.0609       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.692       |\n",
      "|    explained_variance   | 0.911        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 74.8         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 80.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4685        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005536532 |\n",
      "|    clip_fraction        | 0.051       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.665      |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.5        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.000611   |\n",
      "|    value_loss           | 84.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4686        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004014779 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.645      |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.35        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    value_loss           | 71.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4686        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008628671 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.643      |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.000143   |\n",
      "|    value_loss           | 81.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4686        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008156138 |\n",
      "|    clip_fraction        | 0.0969      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.662      |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.92        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    value_loss           | 60.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4686         |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 466944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057858187 |\n",
      "|    clip_fraction        | 0.0679       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.672       |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.52         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 86.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4687        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004997471 |\n",
      "|    clip_fraction        | 0.0457      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.675      |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.8        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.000437   |\n",
      "|    value_loss           | 86.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4687         |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 483328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047983504 |\n",
      "|    clip_fraction        | 0.0478       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.677       |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 64.3         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.000738    |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4687         |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 491520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046743862 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.656       |\n",
      "|    explained_variance   | 0.873        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.000236    |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4683         |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 106          |\n",
      "|    total_timesteps      | 499712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056255665 |\n",
      "|    clip_fraction        | 0.0703       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.667       |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.000285    |\n",
      "|    value_loss           | 24.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4683         |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 507904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032400307 |\n",
      "|    clip_fraction        | 0.0366       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.65        |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.000316    |\n",
      "|    value_loss           | 47.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4683         |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 516096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067512696 |\n",
      "|    clip_fraction        | 0.0664       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.662       |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.000526    |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4682        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004047842 |\n",
      "|    clip_fraction        | 0.0423      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.684      |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | 4.63e-05    |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4682        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006974478 |\n",
      "|    clip_fraction        | 0.0613      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.675      |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.000581   |\n",
      "|    value_loss           | 52          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4680         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 540672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042527346 |\n",
      "|    clip_fraction        | 0.0643       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.649       |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.28         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -7.4e-05     |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4681         |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 548864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039043657 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.672       |\n",
      "|    explained_variance   | 0.864        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.98         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.000713    |\n",
      "|    value_loss           | 64.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4680         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 557056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061366856 |\n",
      "|    clip_fraction        | 0.0604       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.639       |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.18         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.000118    |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4681         |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 565248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066817477 |\n",
      "|    clip_fraction        | 0.0721       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.623       |\n",
      "|    explained_variance   | 0.868        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.000527    |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4681         |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 573440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061844997 |\n",
      "|    clip_fraction        | 0.0755       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.663       |\n",
      "|    explained_variance   | 0.882        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    value_loss           | 47.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4681        |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004912328 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.642      |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 94.3        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | 0.000377    |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4682         |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 589824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069288723 |\n",
      "|    clip_fraction        | 0.0773       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.65        |\n",
      "|    explained_variance   | 0.869        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 72.8         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.000679    |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4682        |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006773527 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.62       |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4683        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005987688 |\n",
      "|    clip_fraction        | 0.0489      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.617      |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.000979   |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4684        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006152711 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.613      |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | 0.000202    |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4684         |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 622592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038602194 |\n",
      "|    clip_fraction        | 0.048        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.656       |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | 0.000307     |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4684         |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 134          |\n",
      "|    total_timesteps      | 630784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049350224 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.646       |\n",
      "|    explained_variance   | 0.842        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | 0.000386     |\n",
      "|    value_loss           | 47.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4685        |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004005665 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.644      |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | 0.00109     |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4686        |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004519622 |\n",
      "|    clip_fraction        | 0.0364      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.635      |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.42        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | 8.15e-06    |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4686         |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 655360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066378545 |\n",
      "|    clip_fraction        | 0.0537       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.635       |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.000399    |\n",
      "|    value_loss           | 30.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4683         |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 663552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043453416 |\n",
      "|    clip_fraction        | 0.0529       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.63        |\n",
      "|    explained_variance   | 0.869        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.17         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.000268    |\n",
      "|    value_loss           | 54.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4684        |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007255383 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.656      |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.1         |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | 0.000332    |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4684         |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 679936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048739533 |\n",
      "|    clip_fraction        | 0.0533       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.648       |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    value_loss           | 28.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4685        |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002395566 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.635      |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9           |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00017    |\n",
      "|    value_loss           | 62.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4681        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004883783 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.647      |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.28        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.000232   |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4680         |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 704512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038424071 |\n",
      "|    clip_fraction        | 0.0587       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.611       |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6            |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | 0.000597     |\n",
      "|    value_loss           | 26.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4679        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007380573 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -2.47e-05   |\n",
      "|    value_loss           | 55.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4679        |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004648857 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.614      |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | 0.000572    |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4679         |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 729088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041213594 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.577       |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 46.3         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -1.61e-05    |\n",
      "|    value_loss           | 40.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4680         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 157          |\n",
      "|    total_timesteps      | 737280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048859646 |\n",
      "|    clip_fraction        | 0.0661       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.543       |\n",
      "|    explained_variance   | 0.916        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.000612    |\n",
      "|    value_loss           | 28.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4680        |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007026576 |\n",
      "|    clip_fraction        | 0.0478      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.558      |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50          |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.00034    |\n",
      "|    value_loss           | 59.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4680         |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 753664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066936905 |\n",
      "|    clip_fraction        | 0.0643       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.29         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | 0.000175     |\n",
      "|    value_loss           | 42           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4680        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005149286 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.593      |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.000428   |\n",
      "|    value_loss           | 81.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4680        |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006976526 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.57       |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.9        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00108    |\n",
      "|    value_loss           | 56          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4679        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005085664 |\n",
      "|    clip_fraction        | 0.0766      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.609      |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.4         |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | 4.82e-05    |\n",
      "|    value_loss           | 53.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4679         |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 786432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059811976 |\n",
      "|    clip_fraction        | 0.0508       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.555       |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.000925    |\n",
      "|    value_loss           | 68.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4678         |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 794624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069632614 |\n",
      "|    clip_fraction        | 0.0922       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.598       |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.4          |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | 3.95e-05     |\n",
      "|    value_loss           | 26.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4678         |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 802816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043084836 |\n",
      "|    clip_fraction        | 0.0676       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.588       |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.000632    |\n",
      "|    value_loss           | 70.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4678        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004035368 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.588      |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.79        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.000382   |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4678        |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006254025 |\n",
      "|    clip_fraction        | 0.0858      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.594      |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.43        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | 1.49e-05    |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4676        |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005636979 |\n",
      "|    clip_fraction        | 0.0583      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.549      |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | 0.000153    |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4675         |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 178          |\n",
      "|    total_timesteps      | 835584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055775577 |\n",
      "|    clip_fraction        | 0.0578       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.541       |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.66         |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.000564    |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4675        |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005570895 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.581      |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.33        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | 0.00145     |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4674        |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004649488 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.584      |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.000491   |\n",
      "|    value_loss           | 51.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4673        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007883661 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.549      |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4670        |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005385858 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.563      |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.000107   |\n",
      "|    value_loss           | 47.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4669        |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004585296 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.544      |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0008     |\n",
      "|    value_loss           | 61.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4669         |\n",
      "|    iterations           | 108          |\n",
      "|    time_elapsed         | 189          |\n",
      "|    total_timesteps      | 884736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070129842 |\n",
      "|    clip_fraction        | 0.071        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.572       |\n",
      "|    explained_variance   | 0.876        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | 0.000553     |\n",
      "|    value_loss           | 52.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 4669       |\n",
      "|    iterations           | 109        |\n",
      "|    time_elapsed         | 191        |\n",
      "|    total_timesteps      | 892928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00667591 |\n",
      "|    clip_fraction        | 0.0599     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.544     |\n",
      "|    explained_variance   | 0.863      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 13         |\n",
      "|    n_updates            | 1080       |\n",
      "|    policy_gradient_loss | -0.000408  |\n",
      "|    value_loss           | 55.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4668         |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 901120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057103466 |\n",
      "|    clip_fraction        | 0.0522       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.861        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 88.7         |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.000919    |\n",
      "|    value_loss           | 66.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4662         |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 195          |\n",
      "|    total_timesteps      | 909312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045730444 |\n",
      "|    clip_fraction        | 0.0653       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.779        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.67         |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.000277    |\n",
      "|    value_loss           | 81.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4660        |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007670926 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.54       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    value_loss           | 82.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4660         |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 925696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071836137 |\n",
      "|    clip_fraction        | 0.0823       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.55        |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.41         |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.000439    |\n",
      "|    value_loss           | 46.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4660        |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004646898 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.516      |\n",
      "|    explained_variance   | 0.83        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 83.3        |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.000224   |\n",
      "|    value_loss           | 60.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4660        |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004815803 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.529      |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44          |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | 0.000794    |\n",
      "|    value_loss           | 57.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4660         |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 203          |\n",
      "|    total_timesteps      | 950272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055145896 |\n",
      "|    clip_fraction        | 0.0948       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.6          |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | 0.000513     |\n",
      "|    value_loss           | 24.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4656         |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 205          |\n",
      "|    total_timesteps      | 958464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043858564 |\n",
      "|    clip_fraction        | 0.0627       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.547       |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.4         |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | -0.00044     |\n",
      "|    value_loss           | 69.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4653        |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006333182 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.546      |\n",
      "|    explained_variance   | 0.893       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 197         |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | 0.000341    |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4653         |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 209          |\n",
      "|    total_timesteps      | 974848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052007874 |\n",
      "|    clip_fraction        | 0.0595       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.544       |\n",
      "|    explained_variance   | 0.863        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 132          |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.000378    |\n",
      "|    value_loss           | 42.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4652        |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005542819 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.535      |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.18        |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.000322   |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4652         |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 213          |\n",
      "|    total_timesteps      | 991232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051214173 |\n",
      "|    clip_fraction        | 0.0819       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.12         |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.000227    |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4652         |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 999424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037880521 |\n",
      "|    clip_fraction        | 0.0527       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.548       |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | 0.000516     |\n",
      "|    value_loss           | 28.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4644        |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007313785 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.534      |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.21        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x162884760>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using .learn method to train the model, setting max time steps to 10,000 across all episodes\n",
    "# Number of epsiodes decided by total_timesteps\n",
    "model.learn(total_timesteps= 1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving of Logs and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../../Training/Saved Models/PPO_lunar_lander')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model back using same vectorised env as above\n",
    "final_model = PPO.load('../../Training/Saved Models/PPO_lunar_lander', env = v_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simybasra/anaconda3/envs/trick_or_retreat/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(258.10781230850046, 12.291696435699995)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deciding to evaluate across 5 episodes\n",
    "evaluate_policy(model, v_env, n_eval_episodes = 10, render = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "**Comment:**\n",
    "\n",
    "`evaluate_policy`: returns average reward and standard deviation of reward\n",
    "\n",
    "**Mean Reward : 258.1**\n",
    "\n",
    "- Average reward across all ten episodes.\n",
    "- Greater than 200 showing agent has learned the task successfully.\n",
    "\n",
    "**Standard Deviation: 12.3**\n",
    "\n",
    "- Shows some variability in agent's performance across episodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2', render_mode = 'human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Number 1 Score:238.45751842581626\n",
      "Episode Number 2 Score:254.75093940235013\n",
      "Episode Number 3 Score:240.75201131445212\n",
      "Episode Number 4 Score:259.60991877764934\n",
      "Episode Number 5 Score:-8.870913497773472\n",
      "Episode Number 6 Score:-15.035203406538315\n",
      "Episode Number 7 Score:236.53993406569455\n",
      "Episode Number 8 Score:264.89932498649733\n",
      "Episode Number 9 Score:214.15074728377326\n",
      "Episode Number 10 Score:1.038238319063737\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    # Resetting env to initial state, ready for testing\n",
    "    obs, _ = env.reset()\n",
    "    score = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Using the model.predict for action selection using policy\n",
    "        action, states = model.predict(obs) \n",
    "        # Take step in the env using chosen action\n",
    "        obs, reward, terminated, truncated, info = env.step(action) \n",
    "        # Update to the score using reward\n",
    "        score+=reward\n",
    "\n",
    "        done = truncated or terminated\n",
    "\n",
    "    print(f'Episode Number {episode} Score:{score}')\n",
    "\n",
    "# Closing after env, no longer needed\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "**Comment:**\n",
    "\n",
    "Overall, agent shows a strong performance with most scores above 200.\n",
    "\n",
    "There are some low and even negative scores which may suggest the agent struggled in certain scenarios. \n",
    "\n",
    "Perhaps worth investigating environment states for poor performing episodes to see what went wrong. Fine-tuning certain hyperparameters could also help improve consistency. However, since Lunar Lander is mainly for gaining experience with OpenAI and Stable Baselines3, I may soon shift to developing my own environment, where I can focus more on fine-tuning and tailoring the agent’s performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the logs in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run in command\n",
    "# navigate to logs for ppo \n",
    "# run tensorboard --logdir=."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give overview of logs in tensorboard!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the agent has clearly produced better results than random action selection. \n",
    "\n",
    "Next, I plan to build a custom environment, implement PPO and potentially explore Q-learning and DQN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Sunday:\n",
    "\n",
    "    - create env\n",
    "\n",
    "Monday\n",
    "\n",
    "    - create env\n",
    "\n",
    "Tuesday\n",
    "\n",
    "    - blog post 2 \n",
    "    - intro, open ai intro, stablebaselines3 into, intro to demos\n",
    "    - get env up and running!\n",
    "\n",
    "Wednesday\n",
    "\n",
    "    - start PPO for own model\n",
    "    - update of blog posts\n",
    "\n",
    "Thursday \n",
    "    \n",
    "    - PPO get sorted \n",
    "    - update blog post ready for publish on Friday AM\n",
    "\n",
    "Friday\n",
    "\n",
    "    - post blog\n",
    "    - look into q learning start to code and do notebook\n",
    "\n",
    "Saturday \n",
    "\n",
    "    - q learning algo research videos/tutorials\n",
    "\n",
    "Sunday \n",
    "\n",
    "    - q learning implement \n",
    "    - try finish q learning\n",
    "\n",
    "Monday \n",
    "\n",
    "    - complete q learning\n",
    "    - look into DQN methods\n",
    "    - things to introduce to env tinker with rnv\n",
    "\n",
    "Tuesday to Friday \n",
    "\n",
    "    - to work on DQN \n",
    "    - try wrap up on Friday \n",
    "    \n",
    "Saturday and Sunday\n",
    "\n",
    "    - to write up final blog post!! \n",
    "    - to post on Monday"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trick_or_retreat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
